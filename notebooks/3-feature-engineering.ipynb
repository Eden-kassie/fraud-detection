{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 3. Feature Engineering\n",
                "\n",
                "This notebook focuses on creating meaningful features for our fraud detection models. We'll process both the fraud and credit card datasets using the logic implemented in `src/features/`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from src.data.loading import load_fraud_data, load_ip_country_data, load_creditcard_data, save_processed_data\n",
                "from src.features.engineering import create_all_features, create_time_features, create_time_since_signup\n",
                "from src.features.geolocation import merge_ip_country, create_country_features\n",
                "from src.data.preprocessing import create_preprocessing_pipeline"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Fraud Dataset Feature Engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load raw data\n",
                "fraud_df = load_fraud_data()\n",
                "ip_df = load_ip_country_data()\n",
                "\n",
                "# 1. Merge with Geolocation\n",
                "merged_df = merge_ip_country(fraud_df, ip_df)\n",
                "\n",
                "# 2. Create categorical features for country risk\n",
                "merged_df = create_country_features(merged_df)\n",
                "\n",
                "# 3. Create time-based features and velocity features\n",
                "# Note: create_all_features() handles time formats and numeric velocity\n",
                "fraud_featured = create_all_features(merged_df)\n",
                "\n",
                "print(f\"Final Fraud Features Shape: {fraud_featured.shape}\")\n",
                "fraud_featured.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Credit Card Dataset Feature Engineering\n",
                "\n",
                "The credit card dataset is mostly pre-processed (PCA). We'll focus on the 'Time' and 'Amount' features."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cc_df = load_creditcard_data()\n",
                "\n",
                "# The 'Time' feature in the credit card dataset represents seconds elapsed since first transaction\n",
                "# We could convert it to hours/days if we had a reference date, but for now we'll keep it numerical\n",
                "cc_featured = cc_df.copy()\n",
                "\n",
                "print(f\"Credit Card Features Shape: {cc_featured.shape}\")\n",
                "cc_featured.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Preprocessing Pipelines\n",
                "\n",
                "Defining and testing our preprocessing logic (scaling and encoding)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example for fraud data\n",
                "numeric_cols = ['purchase_value', 'age', 'time_since_signup', 'user_txn_count', 'user_avg_amount']\n",
                "categorical_cols = ['source', 'browser', 'sex', 'country_risk_level']\n",
                "\n",
                "pipeline = create_preprocessing_pipeline(numeric_cols, categorical_cols, scale_strategy='standard', encoding='onehot')\n",
                "print(\"Preprocessing pipeline created successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Save Processed Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save featured datasets for training step\n",
                "save_processed_data(fraud_featured, \"fraud_featured.csv\")\n",
                "save_processed_data(cc_featured, \"creditcard_featured.csv\")\n",
                "\n",
                "print(\"Datasets saved successfully to data/processed/\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
