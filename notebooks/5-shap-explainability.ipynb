{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 5. Model Explainability with SHAP\n",
                "\n",
                "This notebook uses SHAP (SHapley Additive exPlanations) to interpret our best performing fraud detection model and understand why it makes specific predictions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import shap\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from src.models.evaluation import load_model\n",
                "from src.models.data_prep import prepare_model_data"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Model and Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the best model we saved earlier\n",
                "model = load_model(\"best_fraud_model\")\n",
                "\n",
                "# Load and prepare the data again (using the same settings as training)\n",
                "df = pd.read_csv('../data/processed/fraud_featured.csv')\n",
                "target = 'class'\n",
                "drop_cols = ['user_id', 'signup_time', 'purchase_time', 'device_id', 'ip_address', 'country']\n",
                "numeric_cols = ['purchase_value', 'age', 'time_since_signup', 'user_txn_count', 'user_avg_amount']\n",
                "categorical_cols = ['source', 'browser', 'sex', 'country_risk_level']\n",
                "\n",
                "X_train, X_test, y_train, y_test = prepare_model_data(\n",
                "    df, \n",
                "    target, \n",
                "    numeric_cols, \n",
                "    categorical_cols, \n",
                "    drop_cols=drop_cols,\n",
                "    apply_smote=False  # No need for SMOTE during interpretation\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Generate SHAP Values\n",
                "\n",
                "SHAP values explain the contribution of each feature to the model's output."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Explaining the model using TreeExplainer (assuming XGBoost/LGBM/RF)\n",
                "explainer = shap.TreeExplainer(model)\n",
                "shap_values = explainer.shap_values(X_test)\n",
                "\n",
                "print(\"SHAP values generated.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Global Interpretability\n",
                "\n",
                "Understanding the model's general behavior across all samples."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Summary Plot: Features ranked by importance and their effect direction\n",
                "shap.summary_plot(shap_values, X_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Bar plot of mean magnitude of SHAP values\n",
                "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Local Interpretability\n",
                "\n",
                "Explaining specific transaction predictions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find a fraudulent sample\n",
                "fraud_idx = np.where(y_test == 1)[0][0]\n",
                "\n",
                "# Waterfall plot for a single fraud prediction\n",
                "# Note: waterfall requires an Explanation object or special handling for older SHAP\n",
                "shap.plots.force(explainer.expected_value, shap_values[fraud_idx], X_test.iloc[fraud_idx], matplotlib=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Conclusion\n",
                "\n",
                "SHAP analysis reveals that `time_since_signup` and `user_txn_count` are often the most critical predictors for fraud in e-commerce transactions. This documentation helps in communicating model logic to stakeholders and ensuring fairness/transparency."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
